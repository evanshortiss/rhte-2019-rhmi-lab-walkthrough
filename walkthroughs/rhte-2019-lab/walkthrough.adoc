= Create an Ordering Processing Pipeline


In this walkthrough you will create a simple end-to-end solution for processing
Orders. Using the Red Hat Managed Integration we'll create a fault tolerant,
message-oriented architecture (MOM) that's based on enterprise integration
patterns (EIP) and microservices. An image of the lab architecture is included
below.

Red Hat Managed Integration (RHMI) is built on OpenShift Dedicated (OSD) and
includes Red Hat Agile Integration and Red Hat Open Application Runtimes
(RHOAR) as hosted managed services configured with shared identity configured
using Red Hat Single Sign On (RH SSO). Each of the services you use as part
of this walkthrough can be logged into using the same credentials you used to
login to the Solution Explorer (this UI you're currently using) and OpenShift
Cluster.

The high-level flow in the architecture is described below:

. Customer places an order via Order API:
.. The API microservice is protected using Red Hat 3scale API Management.
.. A single `POST /order` endpoint is exposed.
.. Customers must include their API Key for requests to be validated.
. The API microservice forwards incoming orders to AMQ:
.. AMQ exposes a queue over an AMQP interface.
.. Orders are stored in the queue until Fuse Online can process them.
. Red Hat Fuse Online will dequeue and process each message from AMQ in series:
.. Fuse Online will allow us to create a low-code Fuse microservice.
.. Processing a message involves writing it to a table in PostreSQL.
.. Fuse Online will provide metrics for processing of messages.
. Red Hat Fuse will be used to create a REST API that exposes an internal API for our business:
.. The `GET /orders` endpoint will return all orders in our system.
.. The `POST /orders/{id}/processed` endpoint will mark an order as processed.
. A Node.js application will provide a real-time dashboard that provides order performance metrics:
.. WebSockets will be used to communicate with the Node.js backend for real-time information.
.. Processed vs. unprocessed order counts will be displayed.
. Red Hat Mobile Developer Services will be used to create a Data Synchronisation service:
.. A Mobile/Web client will connect to the service and receive real-time updates.
.. Employees will use the service to mark orders processed.

image::images/architecture.png[integration, role="integr8ly-img-responsive"]

[type=walkthroughResource,serviceName=openshift]
.Red Hat OpenShift
****
* link:{openshift-host}/console[Console, window="_blank"]
* link:https://help.openshift.com/[Openshift Online Help Center, window="_blank"]
* link:https://blog.openshift.com/[Openshift Blog, window="_blank"]
****

[type=walkthroughResource,serviceName=apicurio]
.Apicurito
****
* link:{apicurio-url}[Console, window="_blank", id="resources-apicurio-url"]
****

[type=walkthroughResource,serviceName=fuse]
.Fuse Online
****
* link:{fuse-url}[Console, window="_blank", id="resources-fuse-url"]
* link:https://access.redhat.com/documentation/en-us/red_hat_fuse/7.3/html/integrating_applications_with_fuse_online/index[Documentation, window="_blank"]
* link:https://www.redhat.com/en/technologies/jboss-middleware/fuse-online[Overview, window="_blank"]
****

[type=walkthroughResource,serviceName=amq-online-standard]
.AMQ Online
****
* link:{enmasse-url}[Console, window="_blank", , id="resources-enmasse-url"]
* link:https://access.redhat.com/documentation/en-us/red_hat_amq/7.4/html/using_amq_online_on_openshift_container_platform/index[Documentation, window="_blank"]
* link:https://www.redhat.com/en/technologies/jboss-middleware/amq[Overview, window="_blank"]
****

[type=walkthroughResource,serviceName=codeready]
.CodeReady Workspaces
****
* link:{che-url}[Console, window="_blank"]
* link:https://developers.redhat.com/products/codeready-workspaces/overview/[Overview, window="_blank"]
* link:https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces_for_openshift/1.0.0/[Documentation, window="_blank"]
****
[type=walkthroughResource,serviceName=3scale]
.3Scale
****
* link:https://{user-username}-admin.{openshift-app-host}[Console, window="_blank"]
* link:https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.5/[Documentation, window="_blank"]
* link:https://www.redhat.com/en/technologies/jboss-middleware/3scale[Overview, window="_blank"]

****

[time=8]
== Explore the Project Namespace and Configure PostgreSQL

When you started this walkthrough a *Project* was automatically created on
this OpenShift Cluster for you. link:{openshift-host}/console/project/{walkthrough-namespace}[Click here, window="_blank"]
to open the *Project* in the OpenShift. A PostgreSQL database has already been
deployed into this *Project*. You will be using this database throughout this
walkthrough.

=== Exploring the Project Namespce
You will get familiar with the *Overivew*,
*Deployment Config*, *Deployment*, and *Secrets* screens from the OpenShift
Console in this section.

. Navigate to your link:{openshift-host}/console/project/{walkthrough-namespace}[OpenShift Project Overview, window="_blank"].
. Find the PostgreSQL instance on the *Overview* screen and expand it using the arrow beside it.
. Take note of the various information provided such as the *Image*, *Ports* and reosurce usage graphs.
. Click the *postgresql* name under the *Deployment Config* to view the details of the current *Deployment Config*.
. Select the latest *Deployment* in the *History* list by clicking number with the `(latest)` label.
. The *Deployment* screen contains detailed information about the current deployment.
. Expand the *Resources* item in the side menu and click *Secrets*.
. Select `orders-postgresql` from the list to view the *Secret*. It contains
the following keys and values:
.. A `database-name` with the value `orders`.
.. A `database-user` with the value `{user-sanitized-username}`.
.. A `database-password` with set of 16 random characters.
. If you return to the *Deployment* screen and open the *Environment* tab you
can see how this *Secret* is used to configure the container environment.


=== Configure PostgreSQL
. Navigate to your link:{openshift-host}/console/project/{walkthrough-namespace}[OpenShift Project Overview, window="_blank"].
. Expand the *Applications* section in the side menu and select *Pods*.
. Select the *Pod* with the prefix `postgresql`.
. Select the *Terminal* tab on the *Pod* overview screen. This will provide
you with a shell that you can use to execute commands in the running
PostgreSQL container.
. Start a session with PostgreSQL by entering the `psql` command.
. Connect to the Orders database by entering the `\c orders;` command.
+
. Enter the following SQL statement to create the a `received_orders` table
that the requests sent to the Orders API will ultimately be written to:
+
[subs="attributes+"]
----
CREATE TABLE received_orders (
   id serial NOT NULL PRIMARY KEY,
   item_id int NOT NULL,
   quantity int NOT NULL,
   processed boolean NOT NULL DEFAULT FALSE
);
----

[type=verification]
====
Check that the table was created by issuing the `\d;` command.

Is the `received_orders` table listed?
====

[type=verificationFail]
Verify that you followed each step in the procedure above. Ensure you copy the
SQL statement exactly and issue it when connected to the `orders` database.

[time=5]
== Create an Orders Queue in AMQ Online
Your order processing pipeline needs to be fault tolerant and scalable. Using
the AMQ message broker facilitates loosely coupled, asynchronous communication
between the microservices you deploy in this lab.

For example, if Fuse Online or the PostgreSQL instance were to become
temporarily unavailable it should not prevent a customer sending requests
to the Order API. Using AMQ in this architecture enables you to rollout
internal updates without affecting service availability.

. Open the link:{enmasse-url}[AMQ Online Console, window="_blank"]. Login
if prompted to do so.
. Select *Address* from the side menu.
. Click the *Create* button in the main content area. The *Create new address* dialog appears.
. Enter the `received-orders` in the *Name* field.
. Select `queue` as the *Type*.
. Click *Next*.
. Select `Small Queue` as the *Plan*.
. Click *Next*.
. Verify you've entered the correct information on the *Summary* screen.
. Click *Create*.

[type=verification]
====
Is the `received-orders` queue listed on the *Addresses* screen in AMQ Online?
====

[type=verificationFail]
Ensure you followed each step in the procedure above. Refresh the AMQ
Online UI to verify that it's not a connectivity or UI issue. If the queue does
not appear follow the steps again or contact your administrator.

[time=10]
== Create an OpenAPI Spec for the Order API using Apicurito

. Navigate to the link:{apicurio-url}[Apicurito Console, window="_blank", id="resources-apicurio-url"].
. Step B
. C
. D

[type=verification]
====
Did you successfully download a JSON or YAML API definition file?
====

[type=verificationFail]
Ensure you followed each step in the procedure above. If the download is
failing contact your administrator.

[time=10]
== Generate Code using the OpenAPI Spec

To continue, you must have Node.js version 10 or later installed. The official
link:https://nodejs.org/en/download/[Downloads Page] has installers and source
code. Installation via link:https://github.com/nvm-sh/nvm[NVM] is popular on
macOS and Linux.

This section also requires the ODO command-line tool to be installed.
Installing ODO is straightforward. Download the binary for your system from
the link:https://github.com/openshift/odo/releases[ODO releases page], add
it to your path, and execute `chmod +x` on the binary.

=== Java Developers (Spring): Connecting to AMQ
Follow this section if you'd like to create a Spring application. If you'd
rather use Node.js, scroll down to the next section.

. Generate the boilerplate code for your Orders API by issuing the following command:
+
[subs="attributes+"]
----
npx @openapitools/openapi-generator-cli@cli-4.0.3 generate -i $API_SPEC_FILE -g spring -o $LOCATION
----
+
. TODO: Steps for Java developers to connect to message queue.

{empty} +

Now that you've implemented the code to connect to the orders queue, you can
deploy your application on OpenShift using ODO.

. Run `mvn package` from the Spring project root directory. This generates a
JAR file for Spring the application.
. Login to the OpenShift Cluster using `odo login {openshift-host}`. You'll be
prompted for your username and password.
. Set the current ODO context to the *Project* created for this lab by running
`odo project set {walkthrough-namespace}`.
. Run `odo create java orders-api --binary target/$YOUR_JAR_FILE`, replacing
the `$YOUR_JAR_FILE` variable with the appropriate value.
. Run `odo push` to push the configuration to the OpenShift Project. This will
create a  *Service* and *Deployment* in your OpenShift *Project* to facilitate
running your Java application.
. Finally, run the `odo url create --port 8080` to expose your Spring
application to via an OpenShift *Route*.
. Use cURL or Postman to test your Spring API.

[NOTE]
====
We'll delete this OpenShift Route later since we want to route incoming
requests through the 3scale AMP on the cluster.
====

=== Node.js Developers (Node.js Express): Connecting to AMQ

. Generate the boilerplate code for your Orders API by issuing the following
command:
+
[subs="attributes+"]
----
npx @openapitools/openapi-generator-cli@cli-4.0.3 generate -i $API_SPEC_FILE -g nodejs-server-deprecated -o $LOCATION
----
+
. TODO: Steps for Node.js developers to connect to message queue.

{empty} +

Now that you've implemented the code to connect to the orders queue, you can
deploy your application on OpenShift using ODO.

. Login to the OpenShift Cluster using `odo login {openshift-host}`. You'll be
prompted for your username and password.
. Set the current ODO context to the *Project* created for this lab by running
`odo project set {walkthrough-namespace}`.
. Run `odo create nodejs orders-api` to create the required configuration
files.
. Run `odo push` to push the configuration to the OpenShift Project. This will
create a  *Service* and *Deployment* in your OpenShift *Project* to facilitate
running your Java application.
. Finally, run the `odo url create --port 8080` to expose your Spring
application to via an OpenShift *Route*.
. Use cURL or Postman to test your Spring API.

[type=verification]
====
Is your Node.js or Java application listed on the link:{openshift-host}/console/project/{walkthrough-namespace}[OpenShift Overview]
for your Project? Can you access it via the Route created?
====

[type=verificationFail]
Ensure you followed each step in the procedure above. If the application is not
listed delete the `.odo` directory in your Node.js or Java project root and
retry the ODO commands. Contact and administrator if the problem persists.

[time=10]
== Expose the Order API via 3scale

=== Subtask Title

. Do first step.
. Do second step.

[time=15]
== Create an Integration using Fuse Online

=== Subtask Title

. Do first step.
. Do second step.

[time=15]
== Expose an Internal Orders API using Fuse

=== Subtask Title

. Do first step.
. Do second step.

[time=10]
== Deploy an in-house Mobility Solution with Real-time Sync

=== Subtask Title

. Do first step.
. Do second step.
